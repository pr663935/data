{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbbbd94-c946-4be6-8018-aa86b2d7b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nnunetv2 in /usr/local/lib/python3.11/dist-packages (2.6.2)\n",
      "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: acvl-utils<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.2.5)\n",
      "Requirement already satisfied: dynamic-network-architectures<0.5,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.4.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.16.1)\n",
      "Requirement already satisfied: batchgenerators>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.7.2)\n",
      "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\n",
      "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.5.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.3.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.21)\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.9.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.3)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.10.6)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.13.2)\n",
      "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.8.2)\n",
      "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.1.8)\n",
      "Requirement already satisfied: batchgeneratorsv2>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.3.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\n",
      "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.7.2)\n",
      "Requirement already satisfied: connected-components-3d in /usr/local/lib/python3.11/dist-packages (from acvl-utils<0.3,>=0.2.3->nnunetv2) (3.24.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\n",
      "Requirement already satisfied: unittest2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.6.0)\n",
      "Requirement already satisfied: fft-conv-pytorch in /usr/local/lib/python3.11/dist-packages (from batchgeneratorsv2>=0.3.0->nnunetv2) (1.2.0)\n",
      "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.10.0)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.1)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.3.7)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.11.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.0.19)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.1.2->nnunetv2) (77.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->nnunetv2) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.5.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.1.2->nnunetv2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (2.1.5)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.22.0.dev20250319+cu128)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.34.4)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.6.2)\n",
      "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: traceback2 in /usr/local/lib/python3.11/dist-packages (from unittest2->batchgenerators>=0.25.1->nnunetv2) (1.4.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.1.9)\n",
      "Requirement already satisfied: linecache2 in /usr/local/lib/python3.11/dist-packages (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2) (1.0.0)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell, run this to install the necessary packages\n",
    "!pip install nnunetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b0e0b7-e44b-4b19-b6bd-6260c62aea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n",
      "  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-4vwfdiyp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-4vwfdiyp\n",
      "  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install SimpleITK pandas tqdm\n",
    "\n",
    "# (Optional but recommended) Install hiddenlayer for network architecture plots\n",
    "!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git\n",
    "\n",
    "# Set up the required nnU-Net environment variables.\n",
    "# These paths tell nnU-Net where to find raw data, preprocessed data, and trained models.\n",
    "import os\n",
    "\n",
    "# Create directories for the project\n",
    "os.makedirs(\"./nnUNet_raw\", exist_ok=True)\n",
    "os.makedirs(\"./nnUNet_preprocessed\", exist_ok=True)\n",
    "os.makedirs(\"./nnUNet_results\", exist_ok=True)\n",
    "os.makedirs(\"./data\", exist_ok=True) # Assuming your data is here\n",
    "os.makedirs(\"./my_custom_nnunet\", exist_ok=True) # For our custom code\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ['nnUNet_raw'] = os.path.abspath(\"./nnUNet_raw\")\n",
    "os.environ['nnUNet_preprocessed'] = os.path.abspath(\"./nnUNet_preprocessed\")\n",
    "os.environ['nnUNet_results'] = os.path.abspath(\"./nnUNet_results\")\n",
    "\n",
    "# IMPORTANT: Add our custom code directory to the Python path\n",
    "# This allows nnU-Net to find our custom trainer and model\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"./my_custom_nnunet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ee907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset root: /workspace/Data\n",
      "Processing training & validation sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:15<00:00, 37.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:03, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset.json...\n",
      "\n",
      "Data preparation complete for Dataset501_Pancreas at /workspace/nnUNet_raw/Dataset501_Pancreas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Dataset Pre-processing cell\n",
    "# Conversion of dataset\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------\n",
    "# Resolve dataset root\n",
    "# --------------------\n",
    "\n",
    "# Find the absolute path to \"data\" folder even if notebook runs from subfolder\n",
    "#For Google COLAB /content/MyDrive/...\n",
    "base_dir = (Path(__file__).parent if \"__file__\" in globals() else Path.cwd()) / \"Data\"\n",
    "\n",
    "if not base_dir.exists():\n",
    "    raise FileNotFoundError(f\"Could not find data folder at {base_dir}\")\n",
    "\n",
    "print(\"Using dataset root:\", base_dir)\n",
    "\n",
    "# nnU-Net environment\n",
    "nnunet_raw_dir = Path(os.environ['nnUNet_raw'])\n",
    "dataset_id = 501\n",
    "dataset_name = f\"Dataset{dataset_id:03d}_Pancreas\"\n",
    "task_dir = nnunet_raw_dir / dataset_name\n",
    "\n",
    "# Create nnU-Net dataset directories\n",
    "images_tr_dir = task_dir / 'imagesTr'\n",
    "labels_tr_dir = task_dir / 'labelsTr'\n",
    "images_ts_dir = task_dir / 'imagesTs'\n",
    "\n",
    "images_tr_dir.mkdir(parents=True, exist_ok=True)\n",
    "labels_tr_dir.mkdir(parents=True, exist_ok=True)\n",
    "images_ts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Process Training and Validation Data ---\n",
    "all_files = []\n",
    "for split in ['train', 'validation']:\n",
    "    split_dir = base_dir / split\n",
    "    if not split_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing split folder: {split_dir}\")\n",
    "    for subtype_folder in split_dir.iterdir():\n",
    "        if subtype_folder.is_dir() and 'subtype' in subtype_folder.name:\n",
    "            subtype = int(subtype_folder.name.replace('subtype', ''))\n",
    "            for f in subtype_folder.iterdir():\n",
    "                all_files.append({\n",
    "                    \"path\": f,\n",
    "                    \"subtype\": subtype\n",
    "                })\n",
    "\n",
    "# Create a dictionary to store classification labels\n",
    "classification_labels = {}\n",
    "num_training_cases = 0\n",
    "\n",
    "print(\"Processing training & validation sets...\")\n",
    "for file_info in tqdm(all_files):\n",
    "    file_path = file_info['path']\n",
    "    subtype = file_info['subtype']\n",
    "    \n",
    "    if '_0000.nii.gz' in file_path.name:  # It's an image file\n",
    "        case_id = file_path.name.split('_0000.nii.gz')[0]\n",
    "        new_name = f\"{case_id}_0000.nii.gz\"\n",
    "        shutil.copy(file_path, images_tr_dir / new_name)\n",
    "\n",
    "        classification_labels[case_id] = subtype\n",
    "        num_training_cases += 1\n",
    "\n",
    "    elif file_path.suffixes == ['.nii', '.gz'] and '_0000' not in file_path.stem:\n",
    "        case_id = file_path.name.replace('.nii.gz', '')\n",
    "        new_name = f\"{case_id}.nii.gz\"\n",
    "        shutil.copy(file_path, labels_tr_dir / new_name)\n",
    "\n",
    "# Save classification labels\n",
    "with open(task_dir / 'classification_labels.json', 'w') as f:\n",
    "    json.dump(classification_labels, f, indent=4)\n",
    "\n",
    "# --- Process Test Data ---\n",
    "print(\"\\nProcessing test set...\")\n",
    "test_dir = base_dir / 'test'\n",
    "if test_dir.exists():\n",
    "    for f in tqdm(test_dir.iterdir()):\n",
    "        if f.suffixes == ['.nii', '.gz']:\n",
    "            shutil.copy(f, images_ts_dir / f.name)\n",
    "else:\n",
    "    print(\"⚠️ No test set found, skipping.\")\n",
    "\n",
    "# --- Create dataset.json ---\n",
    "print(\"\\nCreating dataset.json...\")\n",
    "dataset_json = OrderedDict()\n",
    "dataset_json['channel_names'] = {\"0\": \"CT\"}\n",
    "dataset_json['labels'] = {\"background\": 0, \"pancreas\": 1, \"lesion\": 2}\n",
    "dataset_json['num_classification_classes'] = 3  # Subtypes 0,1,2\n",
    "dataset_json['numTraining'] = num_training_cases\n",
    "dataset_json['file_ending'] = \".nii.gz\"\n",
    "\n",
    "with open(task_dir / 'dataset.json', 'w') as f:\n",
    "    json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "print(f\"\\nData preparation complete for {dataset_name} at {task_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9f5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnUNet from Github\n",
    "# pip install https://github.com/MIC-DKFZ/nnUNet.git\n",
    "#nnUNet/nnunetv2/training/nnUNetTrainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724d7635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./my_custom_nnunet/multitask_network.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile ./my_custom_nnunet/multitask_network.py\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simple 3D UNet backbone for demonstration\n",
    "class UNetBackbone(nn.Module):\n",
    "    def __init__(self, in_channels=1, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.Sequential(nn.Conv3d(in_channels, base_channels, 3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv3d(base_channels, base_channels, 3, padding=1),\n",
    "                                  nn.ReLU())\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.enc2 = nn.Sequential(nn.Conv3d(base_channels, base_channels*2, 3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv3d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "                                  nn.ReLU())\n",
    "\n",
    "        self.center = nn.Sequential(nn.Conv3d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv3d(base_channels*4, base_channels*4, 3, padding=1),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(base_channels*4, base_channels*2, kernel_size=2, stride=2)\n",
    "        self.dec2 = nn.Sequential(nn.Conv3d(base_channels*4, base_channels*2, 3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv3d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "                                  nn.ReLU())\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(base_channels*2, base_channels, kernel_size=2, stride=2)\n",
    "        self.dec1 = nn.Sequential(nn.Conv3d(base_channels*2, base_channels, 3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv3d(base_channels, base_channels, 3, padding=1),\n",
    "                                  nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        center = self.center(self.pool(enc2))\n",
    "\n",
    "        dec2 = self.dec2(torch.cat([self.up2(center), enc2], dim=1))\n",
    "        dec1 = self.dec1(torch.cat([self.up1(dec2), enc1], dim=1))\n",
    "        return dec1\n",
    "\n",
    "\n",
    "# Multi-task UNet: segmentation + classification\n",
    "class UNet_MultiTask(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes_seg=2, num_classes_clf=2):\n",
    "        super().__init__()\n",
    "        self.backbone = UNetBackbone(in_channels)\n",
    "        base_channels = 32\n",
    "\n",
    "        # Segmentation head\n",
    "        self.seg_head = nn.Conv3d(base_channels, num_classes_seg, kernel_size=1)\n",
    "\n",
    "        # Classification head (global average pooling -> linear)\n",
    "        self.clf_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(base_channels, num_classes_clf)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        seg_out = self.seg_head(features)\n",
    "        clf_out = self.clf_head(features)\n",
    "        return seg_out, clf_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34791ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nnUNet/nnunetv2/training/nnUNetTrainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b9a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./my_custom_nnunet/nnUNetTrainer_MultiTask.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./my_custom_nnunet/nnUNetTrainer_MultiTask.py\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "from .multitask_network import UNet_MultiTask\n",
    "from nnunetv2.training.loss.compound_losses import DC_and_CE_loss\n",
    "\n",
    "class nnUNetTrainer_MultiTask(nnUNetTrainer):\n",
    "    def initialize_network(self):\n",
    "        \"\"\"Initialize multi-task UNet\"\"\"\n",
    "        self.network = UNet_MultiTask(\n",
    "            in_channels=self.num_input_channels,\n",
    "            num_classes_seg=self.num_classes,\n",
    "            num_classes_clf=2  # Change based on your dataset\n",
    "        ).to(self.device)\n",
    "\n",
    "    def compute_loss(self, x, y):\n",
    "        \"\"\"Compute combined loss for segmentation + classification\"\"\"\n",
    "        # Expect y = (seg_target, clf_target)\n",
    "        seg_target, clf_target = y\n",
    "        seg_pred, clf_pred = self.network(x)\n",
    "\n",
    "        seg_loss = DC_and_CE_loss(seg_pred, seg_target)\n",
    "        clf_loss = nn.CrossEntropyLoss()(clf_pred, clf_target)\n",
    "\n",
    "        total_loss = seg_loss + clf_loss\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af11373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All labels fixed to integer values {0,1,2}\n"
     ]
    }
   ],
   "source": [
    "#COnverison from float to int\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "labels_dir = Path(\"/workspace/nnUNet_raw/Dataset501_Pancreas/labelsTr\") \n",
    "\n",
    "for file in labels_dir.glob(\"*.nii.gz\"):\n",
    "    img = nib.load(str(file))\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Round floats to nearest int and cast\n",
    "    data = np.rint(data).astype(np.int16)\n",
    "\n",
    "    # Verify unique labels\n",
    "    unique = np.unique(data)\n",
    "    if not set(unique).issubset({0, 1, 2}):\n",
    "        print(f\"⚠️ Warning: {file.name} has unexpected labels {unique}\")\n",
    "\n",
    "    # Save back with same affine/header\n",
    "    new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "    nib.save(new_img, str(file))\n",
    "\n",
    "print(\"✅ All labels fixed to integer values {0,1,2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2425f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All labels fixed to exact integers 0, 1, 2 (np.int64)\n"
     ]
    }
   ],
   "source": [
    "#COnverison from float to int64\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "labels_dir = Path(\"/workspace/nnUNet_raw/Dataset501_Pancreas/labelsTr\")\n",
    "\n",
    "for file in labels_dir.glob(\"*.nii.gz\"):\n",
    "    img = nib.load(str(file))\n",
    "    data = img.get_fdata()\n",
    "    \n",
    "    # Round to nearest integer\n",
    "    data = np.round(data).astype(np.int64)\n",
    "    \n",
    "    # Clip any possible out-of-range values just in case\n",
    "    data = np.clip(data, 0, 2)\n",
    "    \n",
    "    # Verify unique labels\n",
    "    unique = np.unique(data)\n",
    "    if not set(unique).issubset({0, 1, 2}):\n",
    "        print(f\"⚠️ Warning: {file.name} has unexpected labels {unique}\")\n",
    "    \n",
    "    # Save back with correct dtype\n",
    "    new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "    nib.save(new_img, str(file))\n",
    "\n",
    "print(\"✅ All labels fixed to exact integers 0, 1, 2 (np.int64)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a5cd25-9151-43ab-b055-ee471aafd7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset501_Pancreas\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "100%|█████████████████████████████████████████| 288/288 [00:09<00:00, 31.97it/s]\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 59.  117.  180.5], 3d_lowres: [59, 117, 180]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 132, 'patch_size': (np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([117. , 180.5]), 'spacing': array([0.73242188, 0.73242188]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': (np.int64(64), np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([ 59. , 117. , 180.5]), 'spacing': array([2.        , 0.73242188, 0.73242188]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /workspace/nnUNet_preprocessed/Dataset501_Pancreas/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset501_Pancreas\n",
      "Configuration: 2d...\n",
      "100%|█████████████████████████████████████████| 288/288 [05:11<00:00,  1.08s/it]\n",
      "Configuration: 3d_fullres...\n",
      "100%|█████████████████████████████████████████| 288/288 [02:32<00:00,  1.89it/s]\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset501_Pancreas. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell\n",
    "!nnUNetv2_plan_and_preprocess -d {dataset_id} --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d995a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "print(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccb5d578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 192, in run_training\n",
      "    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 42, in get_trainer_from_args\n",
      "    raise RuntimeError(f'Could not find requested nnunet trainer {trainer_name} in '\n",
      "RuntimeError: Could not find requested nnunet trainer nnUNetTrainer_MultiTask in nnunetv2.training.nnUNetTrainer (/usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer). If it is located somewhere else, please move it there.\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell\n",
    "# Note: Training all 5 folds is recommended for best performance and ensembling.\n",
    "# Here we train fold 0 as an example.\n",
    "# To train all folds, you would run this command in a loop for fold in [0, 1, 2, 3, 4].\n",
    "# \n",
    "#!nnUNetv2_train {dataset_id} 3d_fullres 0 -tr nnUNetTrainer_MultiTask --npz -num_epochs 10\n",
    "\n",
    "!nnUNet_trainer_class_dir='/workspace/my_custom_nnunet' nnUNetv2_train {dataset_id} 3d_fullres 0 -tr nnUNetTrainer_MultiTask --npz\n",
    "\n",
    "# !nnUNetv2_train 1 3d_fullres 0 -tr nnUNetTrainer_10epochs --num_gpus 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d7c9f3-4403-4167-92ed-cff2aa3fad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 192, in run_training\n",
      "    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 42, in get_trainer_from_args\n",
      "    raise RuntimeError(f'Could not find requested nnunet trainer {trainer_name} in '\n",
      "RuntimeError: Could not find requested nnunet trainer nnUNetTrainer_MultiTask in nnunetv2.training.nnUNetTrainer (/usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer). If it is located somewhere else, please move it there.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ An error occurred while running the command: Command '['nnUNetv2_train', '501', '3d_fullres', '0', '-tr', 'nnUNetTrainer_MultiTask', '--npz']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "##trying t fx above cell here\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Create a copy of the current environment variables\n",
    "env = os.environ.copy()\n",
    "\n",
    "# Set the path to the directory containing your custom trainer class\n",
    "env['nnUNet_trainer_class_dir'] = '/workspace/my_custom_nnunet'\n",
    "\n",
    "# Define the command as a list of strings\n",
    "command = [\n",
    "    'nnUNetv2_train',\n",
    "    '501',  # Replace with {dataset_id} if it's a variable\n",
    "    '3d_fullres',\n",
    "    '0',\n",
    "    '-tr',\n",
    "    'nnUNetTrainer_MultiTask',\n",
    "    '--npz'\n",
    "]\n",
    "\n",
    "# Run the command with the modified environment\n",
    "try:\n",
    "    subprocess.run(command, env=env, check=True)\n",
    "    print(\"✅ Training command executed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"❌ An error occurred while running the command: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the trained model directory\n",
    "model_dir = Path(os.environ['nnUNet_results']) / dataset_name / \"nnUNetTrainer_MultiTask__nnUNetPlans__3d_fullres\"\n",
    "\n",
    "# Find the training plot for fold 0\n",
    "progress_png_path = model_dir / \"fold_0\" / \"progress.png\"\n",
    "\n",
    "if progress_png_path.exists():\n",
    "    print(f\"Displaying training graph from: {progress_png_path}\")\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    img = mpimg.imread(progress_png_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"❌ Could not find training graph at {progress_png_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8990108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_nnunet_log(log_file_path):\n",
    "    \"\"\"\n",
    "    Parses an nnU-Net v2 training log file to extract key metrics per epoch.\n",
    "    \"\"\"\n",
    "    epoch_data = []\n",
    "    \n",
    "    with open(log_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    current_epoch = -1\n",
    "    epoch_metrics = {}\n",
    "\n",
    "    # Regex patterns to find the data we need\n",
    "    epoch_pattern = re.compile(r\"Epoch (\\d+)\")\n",
    "    train_loss_pattern = re.compile(r\"train_loss ([\\-\\d\\.]+)\")\n",
    "    val_loss_pattern = re.compile(r\"val_loss ([\\-\\d\\.]+)\")\n",
    "    ema_dice_pattern = re.compile(r\"New best EMA pseudo Dice: ([\\d\\.]+)\")\n",
    "\n",
    "    for line in lines:\n",
    "        epoch_match = epoch_pattern.search(line)\n",
    "        if epoch_match:\n",
    "            # When we find a new epoch, save the previous one's data\n",
    "            if current_epoch != -1 and 'train_loss' in epoch_metrics:\n",
    "                epoch_data.append(epoch_metrics)\n",
    "            \n",
    "            current_epoch = int(epoch_match.group(1))\n",
    "            epoch_metrics = {'epoch': current_epoch}\n",
    "            # Carry over the last known EMA Dice\n",
    "            if epoch_data:\n",
    "                epoch_metrics['ema_pseudo_dice'] = epoch_data[-1].get('ema_pseudo_dice')\n",
    "\n",
    "        train_loss_match = train_loss_pattern.search(line)\n",
    "        if train_loss_match:\n",
    "            epoch_metrics['train_loss'] = float(train_loss_match.group(1))\n",
    "\n",
    "        val_loss_match = val_loss_pattern.search(line)\n",
    "        if val_loss_match:\n",
    "            epoch_metrics['val_loss'] = float(val_loss_match.group(1))\n",
    "\n",
    "        ema_dice_match = ema_dice_pattern.search(line)\n",
    "        if ema_dice_match:\n",
    "            epoch_metrics['ema_pseudo_dice'] = float(ema_dice_match.group(1))\n",
    "\n",
    "    # Append the last epoch's data\n",
    "    if 'train_loss' in epoch_metrics:\n",
    "        epoch_data.append(epoch_metrics)\n",
    "        \n",
    "    return pd.DataFrame(epoch_data)\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "# **CORRECTED PART**: Use the full path to the log file\n",
    "# We build the path dynamically from the environment variables set earlier.\n",
    "dataset_id = 501\n",
    "dataset_name = f\"Dataset{dataset_id:03d}_Pancreas\"\n",
    "model_folder_path = Path(os.environ['nnUNet_results']) / dataset_name / \"nnUNetTrainer_MultiTask__nnUNetPlans__3d_fullres\" / \"fold_0\"\n",
    "log_filename = 'training_log_2025_9_9_22_44_55.txt'\n",
    "LOG_FILE = model_folder_path / log_filename\n",
    "\n",
    "if not LOG_FILE.exists():\n",
    "    print(f\"❌ ERROR: Log file not found at the specified path: {LOG_FILE}\")\n",
    "    print(\"Please verify the path and filename are correct.\")\n",
    "else:\n",
    "    print(f\"✅ Found log file: {LOG_FILE}\")\n",
    "    log_df = parse_nnunet_log(LOG_FILE)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    ax1.plot(log_df['epoch'], log_df['train_loss'], 'o-', label='Train Loss', color='b')\n",
    "    ax1.plot(log_df['epoch'], log_df['val_loss'], 'o-', label='Validation Loss', color='r')\n",
    "    ax1.set_ylabel('Loss (Dice + CE)')\n",
    "    ax1.set_title('Training and Validation Loss per Epoch')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot EMA Pseudo Dice\n",
    "    ax2.plot(log_df['epoch'], log_df['ema_pseudo_dice'], 'o-', label='EMA Pseudo Dice', color='g')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('EMA Pseudo Dice Score')\n",
    "    ax2.set_title('Validation EMA Pseudo Dice Score per Epoch')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print the final metrics from the dataframe\n",
    "    print(\"\\n--- Parsed Metrics Summary ---\")\n",
    "    print(log_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#aved weights to /mnt/data/weights_epoch50.pth and loss plot to /mnt/data/loss.png\")\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Ensure previous definitions are available ---\n",
    "# Make sure the UNet2D class definition from your training script is in a previous cell.\n",
    "# If not, you must redefine it here.\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_ch=1, base_ch=16, n_classes=3, n_subtypes=3):\n",
    "        super().__init__()\n",
    "        self.down1 = DoubleConv(in_ch, base_ch)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.down2 = DoubleConv(base_ch, base_ch*2)\n",
    "        self.up1 = nn.ConvTranspose2d(base_ch*2, base_ch, 2, stride=2)\n",
    "        self.conv_up = DoubleConv(base_ch*2, base_ch)\n",
    "        self.seg_head = nn.Conv2d(base_ch, n_classes, 1)\n",
    "        self.cls_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.cls_head = nn.Linear(base_ch, n_subtypes)\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        p1 = self.pool(d1)\n",
    "        d2 = self.down2(p1)\n",
    "        u1 = self.up1(d2)\n",
    "        cat = torch.cat([u1, d1], dim=1)\n",
    "        up = self.conv_up(cat)\n",
    "        seg = self.seg_head(up)\n",
    "        pooled = self.cls_pool(up).view(up.size(0), -1)\n",
    "        cls = self.cls_head(pooled)\n",
    "        return seg, cls\n",
    "\n",
    "# --- New Dataset Class for Inference ---\n",
    "# This dataset handles resizing to prevent the RuntimeError.\n",
    "# It only deals with images, as test sets don't have masks.\n",
    "\n",
    "# Define the resizing transform\n",
    "infer_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)), # Resize to a fixed size, e.g., 224x224\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class InferenceSliceDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.slices = []  # List of (image_path, slice_idx)\n",
    "        for img_p in self.image_paths:\n",
    "            try:\n",
    "                nii_img = nib.load(img_p)\n",
    "                nz = nii_img.shape[2]\n",
    "                for s in range(nz):\n",
    "                    self.slices.append((img_p, s))\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read {img_p}. Error: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_p, s_idx = self.slices[idx]\n",
    "        img_data = nib.load(img_p).get_fdata()[:, :, s_idx].astype(np.float32)\n",
    "        \n",
    "        # Normalize image\n",
    "        img_data = (img_data - img_data.mean()) / (img_data.std() + 1e-8)\n",
    "        \n",
    "        # Apply the transform\n",
    "        if self.transform:\n",
    "            # The transform expects a PIL image, so we need to convert the format\n",
    "            img_uint8 = ((img_data - img_data.min()) / (img_data.max() - img_data.min() + 1e-8) * 255).astype(np.uint8)\n",
    "            img_tensor = self.transform(img_uint8)\n",
    "        else:\n",
    "            img_tensor = torch.from_numpy(img_data[np.newaxis, :, :])\n",
    "\n",
    "        return img_tensor, img_p, s_idx\n",
    "\n",
    "# --- Main Inference Logic ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. Load your trained model\n",
    "model = UNet2D(in_ch=1, base_ch=16).to(device)\n",
    "# weights_path = '/mnt/data/weights_epoch50.pth'\n",
    "weights_path = '/nnUNet_results/Dataset501_Pancreas/nnUNetTrainer_MultiTask__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth'\n",
    "if os.path.exists(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "    print(f\"Successfully loaded weights from {weights_path}\")\n",
    "else:\n",
    "    print(f\"Error: Weights file not found at {weights_path}. Please ensure training was completed.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 2. Prepare the test data\n",
    "test_data_root = 'data/test'\n",
    "test_imgs = sorted([os.path.join(test_data_root, f) for f in os.listdir(test_data_root) if f.endswith('_0000.nii.gz')])\n",
    "test_ds = InferenceSliceDataset(test_imgs, transform=infer_transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# 3. Run inference\n",
    "results = {}\n",
    "with torch.no_grad():\n",
    "    for x, paths, slice_indices in tqdm(test_loader, desc=\"Running Inference\"):\n",
    "        x = x.to(device).float()\n",
    "        seg_logits, cls_logits = model(x)\n",
    "        \n",
    "        # Get predictions for the batch\n",
    "        seg_preds = torch.argmax(seg_logits, dim=1).cpu().numpy()\n",
    "        cls_preds = torch.argmax(cls_logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        # Store results slice by slice\n",
    "        for i in range(len(paths)):\n",
    "            path = paths[i]\n",
    "            s_idx = slice_indices[i].item()\n",
    "            \n",
    "            if path not in results:\n",
    "                original_img = nib.load(path)\n",
    "                results[path] = {\n",
    "                    'seg_volume': np.zeros(original_img.shape, dtype=np.uint8),\n",
    "                    'cls_votes': [],\n",
    "                    'affine': original_img.affine,\n",
    "                    'header': original_img.header\n",
    "                }\n",
    "            \n",
    "            # The segmentation needs to be resized back to its original dimensions\n",
    "            # Since this is complex, we will save the resized segmentation for now.\n",
    "            # A more advanced pipeline would handle this.\n",
    "            # For now, we will just store the classification votes.\n",
    "            results[path]['cls_votes'].append(cls_preds[i])\n",
    "\n",
    "# 4. Process and save results\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "classification_results = []\n",
    "\n",
    "print(\"\\nProcessing and saving results...\")\n",
    "for path, data in results.items():\n",
    "    # Final classification is the most frequent vote across all slices\n",
    "    final_subtype = np.bincount(data['cls_votes']).argmax()\n",
    "    \n",
    "    # Filename for submission\n",
    "    base_name = os.path.basename(path).replace('_0000.nii.gz', '.nii.gz')\n",
    "    classification_results.append({'Names': base_name, 'Subtype': final_subtype})\n",
    "    \n",
    "    # For now, we are skipping saving the segmentation masks as it requires\n",
    "    # a reverse-resize operation which complicates the script. The primary\n",
    "    # goal here is to get classification results without the RuntimeError.\n",
    "\n",
    "# 5. Save classification CSV\n",
    "csv_path = os.path.join(output_dir, 'subtype_results.csv')\n",
    "df = pd.DataFrame(classification_results)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Inference complete. Classification results saved to {csv_path}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --- Add these lines to define the necessary variables ---\n",
    "# Define the folder where your test images are located\n",
    "TEST_FOLDER = Path(\"./data/test\") \n",
    "# Define the folder where your segmentation results were saved\n",
    "OUTPUT_FOLDER = Path(\"./results\") \n",
    "# Get the list of test files\n",
    "test_files = sorted(list(TEST_FOLDER.glob('*.nii.gz')))\n",
    "# --- End of added lines ---\n",
    "\n",
    "# Select a random test image and its corresponding predicted segmentation\n",
    "if not test_files:\n",
    "    print(\"❌ No test files found in the specified directory.\")\n",
    "else:\n",
    "    random_test_file = random.choice(test_files)\n",
    "    image_path = random_test_file\n",
    "    seg_path = OUTPUT_FOLDER / random_test_file.name.replace('_0000.nii.gz', '.nii.gz')\n",
    "\n",
    "    print(f\"Visualizing image: {image_path.name}\")\n",
    "    print(f\"Segmentation: {seg_path.name}\")\n",
    "\n",
    "    if not seg_path.exists():\n",
    "        print(\"❌ Segmentation file not found. Skipping visualization.\")\n",
    "    else:\n",
    "        # Load the NIfTI files\n",
    "        img_nib = nib.load(image_path)\n",
    "        img_data = img_nib.get_fdata()\n",
    "        seg_nib = nib.load(seg_path)\n",
    "        seg_data = seg_nib.get_fdata()\n",
    "\n",
    "        # Find a good slice to display (one with a segmentation)\n",
    "        slice_indices = np.where(np.sum(seg_data, axis=(0, 1)) > 0)[0]\n",
    "        if len(slice_indices) > 0:\n",
    "            mid_slice = slice_indices[len(slice_indices) // 2]\n",
    "        else:\n",
    "            mid_slice = img_data.shape[2] // 2\n",
    "\n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        axes[0].imshow(np.rot90(img_data[:, :, mid_slice]), cmap='gray')\n",
    "        axes[0].set_title(f\"Original Image (Slice {mid_slice})\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        axes[1].imshow(np.rot90(img_data[:, :, mid_slice]), cmap='gray')\n",
    "        # Use a masked array to only show non-zero labels\n",
    "        seg_masked = np.ma.masked_where(seg_data[:, :, mid_slice] == 0, seg_data[:, :, mid_slice])\n",
    "        axes[1].imshow(np.rot90(seg_masked), alpha=0.6, cmap='viridis') # 'viridis' shows classes in different colors\n",
    "        axes[1].set_title(\"Segmentation Overlay\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r -q results.zip ./results\n",
    "print(\"✅ Created results.zip containing all test segmentations and the subtype_results.csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference script using nnUNetPredictor (v2 compatible)\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "DATASET_ID = 501\n",
    "TEST_FOLDER = './data/test'       # Folder containing your test NIfTI files\n",
    "OUTPUT_FOLDER = './results'       # Folder to save segmentations\n",
    "SUBMISSION_CSV = os.path.join(OUTPUT_FOLDER, 'subtype_results.csv')\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Find the trained model folder\n",
    "model_folder = os.path.join(\n",
    "    os.environ['nnUNet_results'],\n",
    "    f\"Dataset{DATASET_ID:03d}_Pancreas\",\n",
    "    \"nnUNetTrainer_MultiTask__nnUNetPlans__3d_fullres\"\n",
    ")\n",
    "print(f\"Using model from: {model_folder}\")\n",
    "\n",
    "# --- Initialize Predictor ---\n",
    "predictor = nnUNetPredictor(\n",
    "    tile_step_size=0.5,\n",
    "    use_gaussian=True,\n",
    "    use_mirroring=True,\n",
    "    perform_everything_on_device=True,\n",
    "    device=torch.device('cuda'),\n",
    "    verbose=False,\n",
    "    verbose_preprocessing=False,\n",
    "    allow_tqdm=True\n",
    ")\n",
    "\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "    model_folder,\n",
    "    use_folds=(0,),  # change if you trained multiple folds\n",
    "    checkpoint_name='checkpoint_final.pth'\n",
    ")\n",
    "\n",
    "# --- Run Inference Loop ---\n",
    "test_files = [f for f in os.listdir(TEST_FOLDER) if f.endswith('.nii.gz')]\n",
    "classification_results = []\n",
    "\n",
    "print(\"Starting inference...\")\n",
    "\n",
    "for f in tqdm(test_files):\n",
    "    input_file = os.path.join(TEST_FOLDER, f)\n",
    "    \n",
    "    # Run sequential inference\n",
    "    ret = predictor.predict_from_files_sequential(\n",
    "        [[input_file]],  # list of lists\n",
    "        OUTPUT_FOLDER,\n",
    "        save_probabilities=False,\n",
    "        overwrite=True,\n",
    "        folder_with_segs_from_prev_stage=None\n",
    "    )\n",
    "\n",
    "    # Check if segmentation was returned\n",
    "    if len(ret) == 0:\n",
    "        print(f\"No segmentation produced for {f}, skipping...\")\n",
    "        classification_results.append({\n",
    "            'Names': f,\n",
    "            'Subtype': -1  # or another placeholder for missing prediction\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    seg_data = ret[0]\n",
    "    \n",
    "    # Save segmentation mask\n",
    "    if isinstance(seg_data, np.ndarray):\n",
    "        import SimpleITK as sitk\n",
    "        seg_itk = sitk.GetImageFromArray(seg_data)\n",
    "        img_sitk = sitk.ReadImage(input_file)\n",
    "        seg_itk.CopyInformation(img_sitk)\n",
    "        seg_file = os.path.join(OUTPUT_FOLDER, f.replace('_0000', ''))\n",
    "        sitk.WriteImage(seg_itk, seg_file)\n",
    "    else:\n",
    "        seg_file = os.path.join(OUTPUT_FOLDER, f.replace('_0000', ''))\n",
    "\n",
    "    # Extract classification\n",
    "    if hasattr(seg_data, 'get') and 'logits' in seg_data:\n",
    "        cls_logits = seg_data['logits']\n",
    "        predicted_subtype = int(torch.argmax(cls_logits, dim=1).cpu())\n",
    "    else:\n",
    "        predicted_subtype = -1\n",
    "\n",
    "    classification_results.append({\n",
    "        'Names': os.path.basename(seg_file),\n",
    "        'Subtype': predicted_subtype\n",
    "    })\n",
    "\n",
    "\n",
    "# --- Save Classification CSV ---\n",
    "df = pd.DataFrame(classification_results)\n",
    "df.to_csv(SUBMISSION_CSV, index=False)\n",
    "\n",
    "print(f\"\\nInference complete! Results saved in {OUTPUT_FOLDER}\")\n",
    "print(f\"Classification CSV saved at: {SUBMISSION_CSV}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "output_dir = \"/home/usama/uw_akash2/nnUNet_results/Dataset501_Pancreas/nnUNetTrainer_MultiTask__nnUNetPlans__3d_fullres/inference_results\"\n",
    "\n",
    "# Use the single output file\n",
    "seg_file = os.path.join(output_dir, \"quiz_.nii.gz\")\n",
    "\n",
    "seg_img = nib.load(seg_file)\n",
    "seg_data = seg_img.get_fdata()\n",
    "\n",
    "# If you have the original image to overlay\n",
    "input_file = \"/home/usama/uw_akash2/data/test/quiz_037_0000.nii.gz\"\n",
    "img_nib = nib.load(input_file)\n",
    "img_data = img_nib.get_fdata()\n",
    "\n",
    "# Visualization (middle slice)\n",
    "mid_slice = img_data.shape[2] // 2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_data[:, :, mid_slice], cmap='gray')\n",
    "plt.title(\"Original Image (slice {})\".format(mid_slice))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_data[:, :, mid_slice], cmap='gray')\n",
    "plt.imshow(seg_data[:, :, mid_slice], alpha=0.5, cmap='jet')\n",
    "plt.title(\"Segmentation Overlay\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
